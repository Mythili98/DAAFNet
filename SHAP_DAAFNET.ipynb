{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAPLEY BASED MODEL INTERPRETATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import scipy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold as skf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Function\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ReverseLayerF(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output = grad_output.neg() * ctx.alpha\n",
    "\n",
    "        return output, None\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.activation1 = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride= 1, padding= 2)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.activation2 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, stride= 1, padding= 2)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        residual  = torch.clone(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(self.activation2(self.bn2(x)))\n",
    "        residual = residual.unsqueeze(0)\n",
    "        residual = nn.functional.interpolate(residual, size = [x.shape[1], x.shape[2], x.shape[3]])\n",
    "        residual = residual.squeeze(0)\n",
    "        x = x.clone()  # Ensure that `x` is not a view or a shared tensor\n",
    "        x += residual\n",
    "        return x\n",
    "    \n",
    "\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.T = 384\n",
    "        \n",
    "        # Layer 1\n",
    "        self.conv1 = nn.Conv2d(1, 16, (1, 32), padding = 0)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16, False)\n",
    "        \n",
    "        # Layer 2\n",
    "        self.padding1 = nn.ZeroPad2d((16, 17, 0, 1))\n",
    "        self.conv2 = nn.Conv2d(1, 4, (2, 32))\n",
    "        self.batchnorm2 = nn.BatchNorm2d(4, False)\n",
    "        self.pooling2 = nn.MaxPool2d(2, 4)\n",
    "        \n",
    "        # Layer 3\n",
    "        self.padding2 = nn.ZeroPad2d((2, 1, 4, 3))\n",
    "        self.conv3 = nn.Conv2d(4, 4, (8, 4))\n",
    "        self.batchnorm3 = nn.BatchNorm2d(4, False)\n",
    "        self.pooling3 = nn.MaxPool2d((2, 4))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer 1\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "        # Layer 2\n",
    "        x = self.padding1(x)\n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = self.pooling2(x)\n",
    "        \n",
    "        # Layer 3\n",
    "        x = self.padding2(x)\n",
    "        x = F.elu(self.conv3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = self.pooling3(x)\n",
    "        # FC Layer\n",
    "        x = x.reshape(-1, 4*2*24)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class CNNModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.feature_image = nn.Sequential()\n",
    "        self.feature_image.add_module('f_conv1', nn.Conv2d(in_channels = 5, out_channels = 32, kernel_size= 3, stride= 1, padding= 2))\n",
    "        self.feature_image.add_module('f_resblock1', ResidualBlock(32,32,5))\n",
    "        self.feature_image.add_module('f_resblock2', ResidualBlock(32,64,5))\n",
    "        self.feature_image.add_module('f_resblock3', ResidualBlock(64,128,5))\n",
    "        self.feature_image.add_module('f_adaptiveavgpool', nn.AdaptiveAvgPool2d((15,15)))\n",
    "\n",
    "        self.feature_wave = nn.Sequential()\n",
    "        self.feature_wave.add_module('f_EEGNet',EEGNet())\n",
    "\n",
    "        self.class_classifier = nn.Sequential()\n",
    "        self.class_classifier.add_module('c_fc1', nn.Linear(15 * 15 * 128 + 4*2*24, 1024))\n",
    "        self.class_classifier.add_module('c_bn1', nn.BatchNorm1d(1024))\n",
    "        self.class_classifier.add_module('c_relu1', nn.ReLU(True))\n",
    "        self.class_classifier.add_module('c_drop1', nn.Dropout(0.2))\n",
    "        self.class_classifier.add_module('c_fc2', nn.Linear(1024, 512))\n",
    "        self.class_classifier.add_module('c_bn2', nn.BatchNorm1d(512))\n",
    "        self.class_classifier.add_module('c_relu2', nn.ReLU(True))\n",
    "        self.class_classifier.add_module('c_fc3', nn.Linear(512, 2))\n",
    "        self.class_classifier.add_module('c_softmax', nn.Softmax(dim = 1))\n",
    "\n",
    "        self.domain_classifier = nn.Sequential()\n",
    "        self.domain_classifier.add_module('d_fc1', nn.Linear(15 * 15 * 128 + 4*2*24, 1024))\n",
    "        self.domain_classifier.add_module('d_bn1', nn.BatchNorm1d(1024))\n",
    "        self.domain_classifier.add_module('d_relu1', nn.ReLU(True))\n",
    "        self.domain_classifier.add_module('d_fc2', nn.Linear(1024, 2))\n",
    "        self.domain_classifier.add_module('d_softmax', nn.Softmax(dim = 1))\n",
    "    \n",
    "\n",
    "    def forward(self, input_data, input_wave):\n",
    "        alpha = 0\n",
    "        feature1 = self.feature_image(input_data)\n",
    "        feature2 = self.feature_wave(input_wave)\n",
    "        feature1 = feature1.view(-1, 15 * 15 * 128)\n",
    "        feature = torch.cat((feature1,feature2),1)\n",
    "        reverse_feature = ReverseLayerF.apply(feature, alpha)\n",
    "        class_output = self.class_classifier(feature)\n",
    "        domain_output = self.domain_classifier(reverse_feature)\n",
    "        return class_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed trial 0\n",
      "Completed trial 1\n",
      "Completed trial 2\n",
      "Completed trial 3\n",
      "Completed trial 4\n",
      "Completed trial 5\n",
      "Completed trial 6\n",
      "Completed trial 7\n",
      "Completed trial 8\n",
      "Completed trial 9\n",
      "Completed trial 10\n",
      "Completed trial 11\n",
      "Completed trial 12\n",
      "Completed trial 13\n",
      "Completed trial 14\n",
      "Completed trial 15\n",
      "Completed trial 16\n",
      "Completed trial 17\n",
      "Completed trial 18\n",
      "Completed trial 19\n",
      "Completed trial 20\n",
      "Completed trial 21\n",
      "Completed trial 22\n",
      "Completed trial 23\n",
      "Completed trial 24\n",
      "Completed trial 25\n",
      "Completed trial 26\n",
      "Completed trial 27\n",
      "Completed trial 28\n",
      "Completed trial 29\n",
      "Completed trial 30\n",
      "Completed trial 31\n",
      "Completed trial 32\n",
      "Completed trial 33\n",
      "Completed trial 34\n",
      "Completed trial 35\n",
      "Completed trial 36\n",
      "Completed trial 37\n",
      "Completed trial 38\n",
      "Completed trial 39\n",
      "Completed trial 0\n",
      "Completed trial 1\n",
      "Completed trial 2\n",
      "Completed trial 3\n",
      "Completed trial 4\n",
      "Completed trial 5\n",
      "Completed trial 6\n",
      "Completed trial 7\n",
      "Completed trial 8\n",
      "Completed trial 9\n",
      "Completed trial 10\n",
      "Completed trial 11\n",
      "Completed trial 12\n",
      "Completed trial 13\n",
      "Completed trial 14\n",
      "Completed trial 15\n",
      "Completed trial 16\n",
      "Completed trial 17\n",
      "Completed trial 18\n",
      "Completed trial 19\n",
      "Completed trial 20\n",
      "Completed trial 21\n",
      "Completed trial 22\n",
      "Completed trial 23\n",
      "Completed trial 24\n",
      "Completed trial 25\n",
      "Completed trial 26\n",
      "Completed trial 27\n",
      "Completed trial 28\n",
      "Completed trial 29\n",
      "Completed trial 30\n",
      "Completed trial 31\n",
      "Completed trial 32\n",
      "Completed trial 33\n",
      "Completed trial 34\n",
      "Completed trial 35\n",
      "Completed trial 36\n",
      "Completed trial 37\n",
      "Completed trial 38\n",
      "Completed trial 39\n"
     ]
    }
   ],
   "source": [
    "## Load data\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, data_img,data_wave,info):\n",
    "        #data loading\n",
    "        self.x1 = data_img\n",
    "        self.x2 = data_wave\n",
    "        self.y = info\n",
    "        self.n_samples = data_img.shape[0]\n",
    "\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        t1 = self.x1[index]\n",
    "        t3 = self.x2[index]\n",
    "        t2 = self.y[index]\n",
    "        t1 = torch.tensor(t1)\n",
    "        t1 = t1.permute((2,0,1))\n",
    "        t2 = torch.tensor(t2)\n",
    "        t3 = torch.tensor(t3)\n",
    "        return (t1,t3,t2)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "data = scipy.io.loadmat('/home/desktop/Desktop/22104412_Docs/EEG-COGMusic/DA-AFNet/datasets/Zscore_clipped/s15_datasets_Zscore_clipped.mat')\n",
    "\n",
    "x_c=data['coh']\n",
    "x_p = data['pli']\n",
    "x_d = data['psd']\n",
    "labels_skf = data['labels_kfold']\n",
    "labels = data['valence']\n",
    "de = data['EEGNet']\n",
    "\n",
    "x_n = np.zeros((40,75,32,32,5))\n",
    "for trial in range(x_n.shape[0]):\n",
    "    for sample in range(x_n.shape[1]):\n",
    "        x_n[trial,sample,:,:,0] = x_c[trial,sample,:,:,0]+np.transpose(x_p[trial,sample,:,:,0])\n",
    "        x_n[trial,sample,:,:,1] = x_c[trial,sample,:,:,1]+np.transpose(x_p[trial,sample,:,:,1])\n",
    "        x_n[trial,sample,:,:,2] = x_c[trial,sample,:,:,2]+np.transpose(x_p[trial,sample,:,:,2])\n",
    "        x_n[trial,sample,:,:,3] = x_c[trial,sample,:,:,3]+np.transpose(x_p[trial,sample,:,:,3])\n",
    "        x_n[trial,sample,:,:,4] = x_c[trial,sample,:,:,4]+np.transpose(x_p[trial,sample,:,:,4])\n",
    "    print(f'Completed trial {trial}')\n",
    "\n",
    "for trial in range(x_n.shape[0]):\n",
    "    for sample in range(x_n.shape[1]):\n",
    "        for i in range(32):\n",
    "            x_n[trial,sample,i,i,:] = x_d[trial,sample,i,:]\n",
    "    print(f'Completed trial {trial}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35,)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = labels_skf[:,0]\n",
    "indices = np.where((v>5.5)|(v<4.5))[0]\n",
    "indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = x_n[indices]\n",
    "labels = labels[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_skf = np.zeros([40,1])\n",
    "l_skf[np.where(labels_skf[:,0]>5)[0]] = 1\n",
    "l_skf = l_skf[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 75, 1, 384, 32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de = de.transpose((0,1,3,2))\n",
    "de = de[indices,:,np.newaxis,:,:]\n",
    "de.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 running\n"
     ]
    }
   ],
   "source": [
    "kf = skf(n_splits = 10)\n",
    "log_pred_dict = {}\n",
    "best_Acc = 0\n",
    "for k,(train_index,test_index) in enumerate(kf.split(dt, l_skf)):\n",
    "    if k == 4:\n",
    "        print(f'Fold {k+1} running')\n",
    "        deTr,deV = np.concatenate(de[train_index],0), np.concatenate(de[test_index],0)\n",
    "        dataTr, dataV = np.concatenate(dt[train_index],0), np.concatenate(dt[test_index],0)\n",
    "        labelsTr, labelsV = np.concatenate(labels[train_index],0), np.concatenate(labels[test_index],0)\n",
    "        ## parameters\n",
    "        bs = 300\n",
    "        image_size = 32\n",
    "        n_epoch = 50\n",
    "    \n",
    "        testDS = Dataset(dataV,deV,labelsV)\n",
    "        testDL = DataLoader(dataset = testDS, batch_size = bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load Model and test data loader\n",
    "model = CNNModel()\n",
    "model.load_state_dict(torch.load('/home/desktop/Desktop/22104412_Docs/EEG-COGMusic/DA-AFNet/models/model_best_49_4_92.33333333333333.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since shuffle=True, this is a random sample of test data\n",
    "batch = next(iter(testDL))\n",
    "images,waves, labels = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 for target dataset is 51.666666666666664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "51.666666666666664"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data\n",
    "\n",
    "\n",
    "def test(dataset_loader,epoch,model,name):\n",
    "    cuda = True\n",
    "    cudnn.benchmark = True\n",
    "    image_size = 32\n",
    "    alpha = 0\n",
    "\n",
    "    dataloader = dataset_loader\n",
    "\n",
    "    \"\"\" training \"\"\"\n",
    "\n",
    "    my_net = model\n",
    "    my_net = my_net.eval()\n",
    "\n",
    "    if cuda:\n",
    "        my_net = my_net.cuda()\n",
    "\n",
    "    len_dataloader = len(dataloader)\n",
    "    data_target_iter = iter(dataloader)\n",
    "\n",
    "    i = 0\n",
    "    n_total = 0\n",
    "    n_correct = 0\n",
    "\n",
    "    while i < len_dataloader:\n",
    "\n",
    "        # test model using target data\n",
    "        data_target = next(data_target_iter)\n",
    "        test_img,test_wave, test_label = data_target\n",
    "\n",
    "        batch_size = len(test_label)\n",
    "\n",
    "        if cuda:\n",
    "            test_img = test_img.cuda()\n",
    "            test_wave = test_wave.cuda()\n",
    "            test_label = test_label.cuda()\n",
    "\n",
    "        class_output = my_net(input_data=test_img.float(), input_wave = test_wave.float())\n",
    "        _,pred = torch.max(class_output, dim=1)\n",
    "        _,gt = torch.max(test_label,dim=1)\n",
    "        n_correct += (pred == gt).sum().item()\n",
    "        n_total += batch_size\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    accu = 100*n_correct/ n_total\n",
    "    print(f'Epoch {epoch} for {name} dataset is {accu}')\n",
    "    return accu\n",
    "\n",
    "test(testDL, 100, model, 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([300, 5, 32, 32]),\n",
       " torch.Size([300, 1, 384, 32]),\n",
       " torch.Size([300, 2]))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape, waves.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   5,   6,   7,   9,  11,  17,  18,  19,  20,  21,  22,  23,\n",
       "        24,  25,  26,  29,  30,  32,  34,  36,  37,  42,  43,  45,  47,\n",
       "        49,  53,  56,  57,  58,  59,  62,  63,  66,  68,  74,  82,  86,\n",
       "        89,  90,  97,  98,  99, 101, 106, 108, 111, 112, 114, 116, 119,\n",
       "       120, 121, 122, 123, 125, 128, 130, 131, 132, 134, 135, 136, 140,\n",
       "       141, 142, 144, 147, 151, 152, 155, 156, 159, 161, 164, 166, 168,\n",
       "       169, 170, 171, 172, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
       "       184, 185, 186, 188, 189, 190, 191, 192, 194, 195, 196, 197, 198,\n",
       "       199, 200, 201, 203, 206, 207, 209, 210, 217, 219, 223, 227, 229,\n",
       "       230, 231, 234, 236, 239, 240, 242, 243, 244, 245, 246, 248, 249,\n",
       "       252, 256, 260, 263, 265, 266, 269, 270, 275, 276, 278, 282, 283,\n",
       "       287, 290, 291, 293, 294, 296, 298])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = np.where(labels == 1)[1]\n",
    "np.where(l ==  1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_images = images\n",
    "test_images = images\n",
    "background_waves = waves\n",
    "test_waves = waves\n",
    "\n",
    "# If the model outputs a tuple and you want to use the first output for SHAP\n",
    "explainer = shap.GradientExplainer(\n",
    "    model, \n",
    "    [background_images.float().to('cuda'), background_waves.float().to('cuda')] # This will specify the first output if the model returns a tuple\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values([test_images.float().to('cuda'), test_waves.float().to('cuda')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300, 5, 32, 32, 2), (300, 1, 384, 32, 2))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_values[0].shape, shap_values[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([300, 5, 32, 32]), torch.Size([300, 1, 384, 32]))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background_images.shape, background_waves.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# shap.image_plot(shap_values[0][0, 0, :, :, :], test_images[0, 0, :, :].numpy(), cmap='viridis')\n",
    "# shap.image_plot(shap_values[0][0, 1, :, :, :], test_images[0, 1, :, :].numpy(), cmap='viridis')\n",
    "# shap.image_plot(shap_values[0][0, 2, :, :, :], test_images[0, 2, :, :].numpy(), cmap='viridis')\n",
    "# shap.image_plot(shap_values[0][0, 3, :, :, :], test_images[0, 3, :, :].numpy(), cmap='viridis')\n",
    "# shap.image_plot(shap_values[0][0, 4, :, :, :], test_images[0, 4, :, :].numpy(), cmap='viridis')  \n",
    "\n",
    "\n",
    "# shap.image_plot(\n",
    "#     shap_values[1][0, 0, 0:128, :, :].transpose((1, 0, 2)), \n",
    "#     test_waves[0, 0, 0:128, :].numpy().transpose((1, 0)), \n",
    "#     cmap='viridis'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 5, 2)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 5 channel wise features\n",
    "\n",
    "shap_values_images = shap_values[0]\n",
    "shap_values_images = shap_values_images.reshape((300,5,-1,2))\n",
    "shap_values_images = np.sum(shap_values_images, axis = 2)\n",
    "shap_values_images.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 1, 2)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 1 spatio-temporal feature\n",
    "\n",
    "shap_values_waves = shap_values[1]\n",
    "shap_values_waves = shap_values_waves.reshape((300,1,-1,2))\n",
    "shap_values_waves = np.sum(shap_values_waves, axis = 2)\n",
    "shap_values_waves.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 6, 2)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_values = np.concatenate((shap_values_images, shap_values_waves), axis = 1)\n",
    "shap_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([300, 5, 1024]), torch.Size([300, 1, 12288]))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## reshape inputs for the shap plots\n",
    "\n",
    "test_images = test_images.reshape((300,5,-1))\n",
    "test_waves = test_waves.reshape((300,1,-1))\n",
    "test_images.shape, test_waves.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300, 5), (300, 1))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images = np.sum(test_images.numpy(), axis = 2)\n",
    "test_waves = np.sum(test_waves.numpy(), axis = 2)\n",
    "\n",
    "test_images.shape, test_waves.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 6)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.concatenate((test_images, test_waves), axis = 1)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "shap.summary_plot(shap_values[:,:,0], X_test, feature_names=[\"Theta band\", \"Alpha band\", \"Beta_low band\", \"Beta_high band\", \"Gamma band\", \"Raw_EEG\"],show=False)\n",
    "plt.title(\"SHAP summary plot for low valence class\")\n",
    "plt.savefig(\"c0.pdf\", format=\"pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "shap.summary_plot(shap_values[:,:,1], X_test, feature_names=[\"Theta band\", \"Alpha band\", \"Beta_low band\", \"Beta_high band\", \"Gamma band\", \"Raw_EEG\"], show=False)\n",
    "plt.title(\"SHAP summary plot for high valence class\")\n",
    "plt.savefig(\"c1.pdf\", format=\"pdf\", bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogmusic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
